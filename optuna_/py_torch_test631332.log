Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =2, wave_type = db1, mode_type = zero,num_encoder_size = 1, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 1 
Epoch [10/30], Train Loss: 0.3006, Val Loss: 0.2519
Epoch [20/30], Train Loss: 0.2662, Val Loss: 0.2277
Epoch [30/30], Train Loss: 0.2363, Val Loss: 0.1987
Total Model Running Time: 180.48 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =2, wave_type = db1, mode_type = zero, num_encoder_size=1, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 1 : 0.1864
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =3, wave_type = db1, mode_type = zero,num_encoder_size = 1, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 1 
Epoch [10/30], Train Loss: 0.3028, Val Loss: 0.2528
Epoch [20/30], Train Loss: 0.2765, Val Loss: 0.2326
Epoch [30/30], Train Loss: 0.2326, Val Loss: 0.1949
Total Model Running Time: 182.29 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =3, wave_type = db1, mode_type = zero, num_encoder_size=1, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 1 : 0.1823
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =2, wave_type = haar, mode_type = zero,num_encoder_size = 1, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 1 
Epoch [10/30], Train Loss: 0.3009, Val Loss: 0.2511
Epoch [20/30], Train Loss: 0.2770, Val Loss: 0.2331
Epoch [30/30], Train Loss: 0.2358, Val Loss: 0.1984
Total Model Running Time: 181.94 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =2, wave_type = haar, mode_type = zero, num_encoder_size=1, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 1 : 0.1859
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =3, wave_type = haar, mode_type = zero,num_encoder_size = 1, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 1 
Epoch [10/30], Train Loss: 0.3018, Val Loss: 0.2511
Epoch [20/30], Train Loss: 0.2647, Val Loss: 0.2218
Epoch [30/30], Train Loss: 0.2253, Val Loss: 0.2029
Total Model Running Time: 181.91 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =3, wave_type = haar, mode_type = zero, num_encoder_size=1, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 1 : 0.1797
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =2, wave_type = db1, mode_type = symmetric,num_encoder_size = 1, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 1 
Epoch [10/30], Train Loss: 0.2981, Val Loss: 0.2465
Epoch [20/30], Train Loss: 0.2644, Val Loss: 0.2230
Epoch [30/30], Train Loss: 0.2323, Val Loss: 0.1981
Total Model Running Time: 185.27 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =2, wave_type = db1, mode_type = symmetric, num_encoder_size=1, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 1 : 0.1864
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =3, wave_type = db1, mode_type = symmetric,num_encoder_size = 1, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 1 
Epoch [10/30], Train Loss: 0.2986, Val Loss: 0.2516
Epoch [20/30], Train Loss: 0.2581, Val Loss: 0.2139
Epoch [30/30], Train Loss: 0.2307, Val Loss: 0.1933
Total Model Running Time: 183.95 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =3, wave_type = db1, mode_type = symmetric, num_encoder_size=1, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 1 : 0.1822
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =2, wave_type = haar, mode_type = symmetric,num_encoder_size = 1, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 1 
Epoch [10/30], Train Loss: 0.2994, Val Loss: 0.2505
Epoch [20/30], Train Loss: 0.2875, Val Loss: 0.2437
Epoch [30/30], Train Loss: 0.2401, Val Loss: 0.2034
Total Model Running Time: 181.77 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =2, wave_type = haar, mode_type = symmetric, num_encoder_size=1, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 1 : 0.1921
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =3, wave_type = haar, mode_type = symmetric,num_encoder_size = 1, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 1 
Epoch [10/30], Train Loss: 0.3014, Val Loss: 0.2509
Epoch [20/30], Train Loss: 0.2766, Val Loss: 0.2358
Epoch [30/30], Train Loss: 0.2310, Val Loss: 0.1945
Total Model Running Time: 183.51 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =3, wave_type = haar, mode_type = symmetric, num_encoder_size=1, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 1 : 0.1823
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =2, wave_type = db1, mode_type = zero,num_encoder_size = 1, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 3 
Epoch [10/30], Train Loss: 0.2969, Val Loss: 0.2665
Epoch [20/30], Train Loss: 0.2565, Val Loss: 0.2471
Epoch [30/30], Train Loss: 0.2250, Val Loss: 0.2210
Total Model Running Time: 290.24 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =2, wave_type = db1, mode_type = zero, num_encoder_size=1, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 3 : 0.2019
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =3, wave_type = db1, mode_type = zero,num_encoder_size = 1, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 3 
Epoch [10/30], Train Loss: 0.3084, Val Loss: 0.2715
Epoch [20/30], Train Loss: 0.2900, Val Loss: 0.2599
Epoch [30/30], Train Loss: 0.2639, Val Loss: 0.2500
Total Model Running Time: 285.53 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =3, wave_type = db1, mode_type = zero, num_encoder_size=1, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 3 : 0.2400
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =2, wave_type = haar, mode_type = zero,num_encoder_size = 1, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 3 
Epoch [10/30], Train Loss: 0.2979, Val Loss: 0.2688
Epoch [20/30], Train Loss: 0.2948, Val Loss: 0.2651
Epoch [30/30], Train Loss: 0.2807, Val Loss: 0.2627
Total Model Running Time: 283.60 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =2, wave_type = haar, mode_type = zero, num_encoder_size=1, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 3 : 0.2465
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =3, wave_type = haar, mode_type = zero,num_encoder_size = 1, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 3 
Epoch [10/30], Train Loss: 0.3010, Val Loss: 0.2627
Epoch [20/30], Train Loss: 0.2640, Val Loss: 0.2426
Epoch [30/30], Train Loss: 0.2229, Val Loss: 0.2156
Total Model Running Time: 287.76 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =3, wave_type = haar, mode_type = zero, num_encoder_size=1, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 3 : 0.2029
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =2, wave_type = db1, mode_type = symmetric,num_encoder_size = 1, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 3 
Epoch [10/30], Train Loss: 0.2970, Val Loss: 0.2641
Epoch [20/30], Train Loss: 0.2682, Val Loss: 0.2464
Epoch [30/30], Train Loss: 0.2252, Val Loss: 0.2364
Total Model Running Time: 289.98 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =2, wave_type = db1, mode_type = symmetric, num_encoder_size=1, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 3 : 0.2021
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =3, wave_type = db1, mode_type = symmetric,num_encoder_size = 1, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 3 
Epoch [10/30], Train Loss: 0.2990, Val Loss: 0.2679
Epoch [20/30], Train Loss: 0.2552, Val Loss: 0.2381
Epoch [30/30], Train Loss: 0.2185, Val Loss: 0.2148
Total Model Running Time: 290.58 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =3, wave_type = db1, mode_type = symmetric, num_encoder_size=1, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 3 : 0.1972
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =2, wave_type = haar, mode_type = symmetric,num_encoder_size = 1, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 3 
Epoch [10/30], Train Loss: 0.3004, Val Loss: 0.2773
Epoch [20/30], Train Loss: 0.2738, Val Loss: 0.2615
Epoch [30/30], Train Loss: 0.2283, Val Loss: 0.2189
Total Model Running Time: 291.85 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =2, wave_type = haar, mode_type = symmetric, num_encoder_size=1, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 3 : 0.2034
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =3, wave_type = haar, mode_type = symmetric,num_encoder_size = 1, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 3 
Epoch [10/30], Train Loss: 0.3005, Val Loss: 0.2696
Epoch [20/30], Train Loss: 0.2808, Val Loss: 0.2587
Epoch [30/30], Train Loss: 0.2358, Val Loss: 0.2218
Total Model Running Time: 290.96 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =3, wave_type = haar, mode_type = symmetric, num_encoder_size=1, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 3 : 0.2086
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =2, wave_type = db1, mode_type = zero,num_encoder_size = 1, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 1 
Epoch [10/30], Train Loss: 0.2971, Val Loss: 0.2486
Epoch [20/30], Train Loss: 0.2617, Val Loss: 0.2194
Epoch [30/30], Train Loss: 0.2333, Val Loss: 0.1933
Total Model Running Time: 214.86 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =2, wave_type = db1, mode_type = zero, num_encoder_size=1, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 1 : 0.1803
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =3, wave_type = db1, mode_type = zero,num_encoder_size = 1, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 1 
Epoch [10/30], Train Loss: 0.3015, Val Loss: 0.2510
Epoch [20/30], Train Loss: 0.2653, Val Loss: 0.2211
Epoch [30/30], Train Loss: 0.2338, Val Loss: 0.1965
Total Model Running Time: 214.26 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =3, wave_type = db1, mode_type = zero, num_encoder_size=1, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 1 : 0.1833
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =2, wave_type = haar, mode_type = zero,num_encoder_size = 1, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 1 
Epoch [10/30], Train Loss: 0.2991, Val Loss: 0.2492
Epoch [20/30], Train Loss: 0.2654, Val Loss: 0.2191
Epoch [30/30], Train Loss: 0.2371, Val Loss: 0.1980
Total Model Running Time: 212.36 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =2, wave_type = haar, mode_type = zero, num_encoder_size=1, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 1 : 0.1843
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =3, wave_type = haar, mode_type = zero,num_encoder_size = 1, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 1 
Epoch [10/30], Train Loss: 0.2971, Val Loss: 0.2474
Epoch [20/30], Train Loss: 0.2569, Val Loss: 0.2157
Epoch [30/30], Train Loss: 0.2310, Val Loss: 0.1944
Total Model Running Time: 213.45 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =3, wave_type = haar, mode_type = zero, num_encoder_size=1, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 1 : 0.1822
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =2, wave_type = db1, mode_type = symmetric,num_encoder_size = 1, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 1 
Epoch [10/30], Train Loss: 0.3010, Val Loss: 0.2507
Epoch [20/30], Train Loss: 0.2592, Val Loss: 0.2162
Epoch [30/30], Train Loss: 0.2305, Val Loss: 0.1952
Total Model Running Time: 214.94 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =2, wave_type = db1, mode_type = symmetric, num_encoder_size=1, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 1 : 0.1823
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =3, wave_type = db1, mode_type = symmetric,num_encoder_size = 1, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 1 
Epoch [10/30], Train Loss: 0.3038, Val Loss: 0.2507
Epoch [20/30], Train Loss: 0.2714, Val Loss: 0.2233
Epoch [30/30], Train Loss: 0.2373, Val Loss: 0.2002
Total Model Running Time: 216.96 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =3, wave_type = db1, mode_type = symmetric, num_encoder_size=1, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 1 : 0.1858
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =2, wave_type = haar, mode_type = symmetric,num_encoder_size = 1, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 1 
Epoch [10/30], Train Loss: 0.2999, Val Loss: 0.2494
Epoch [20/30], Train Loss: 0.2669, Val Loss: 0.2237
Epoch [30/30], Train Loss: 0.2344, Val Loss: 0.1970
Total Model Running Time: 216.30 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =2, wave_type = haar, mode_type = symmetric, num_encoder_size=1, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 1 : 0.1842
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =3, wave_type = haar, mode_type = symmetric,num_encoder_size = 1, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 1 
Epoch [10/30], Train Loss: 0.2996, Val Loss: 0.2486
Epoch [20/30], Train Loss: 0.2602, Val Loss: 0.2180
Epoch [30/30], Train Loss: 0.2372, Val Loss: 0.2000
Total Model Running Time: 216.98 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =3, wave_type = haar, mode_type = symmetric, num_encoder_size=1, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 1 : 0.1877
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =2, wave_type = db1, mode_type = zero,num_encoder_size = 1, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 3 
Epoch [10/30], Train Loss: 0.3008, Val Loss: 0.2715
Epoch [20/30], Train Loss: 0.2812, Val Loss: 0.2573
Epoch [30/30], Train Loss: 0.2442, Val Loss: 0.2379
Total Model Running Time: 338.75 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =2, wave_type = db1, mode_type = zero, num_encoder_size=1, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 3 : 0.2178
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =3, wave_type = db1, mode_type = zero,num_encoder_size = 1, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 3 
Epoch [10/30], Train Loss: 0.3009, Val Loss: 0.2705
Epoch [20/30], Train Loss: 0.2848, Val Loss: 0.2577
Epoch [30/30], Train Loss: 0.2241, Val Loss: 0.2145
Total Model Running Time: 335.15 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =3, wave_type = db1, mode_type = zero, num_encoder_size=1, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 3 : 0.2009
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =2, wave_type = haar, mode_type = zero,num_encoder_size = 1, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 3 
Epoch [10/30], Train Loss: 0.3043, Val Loss: 0.2677
Early stopping triggered
Total Model Running Time: 165.43 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =2, wave_type = haar, mode_type = zero, num_encoder_size=1, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 3 : 0.2572
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =3, wave_type = haar, mode_type = zero,num_encoder_size = 1, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 3 
Epoch [10/30], Train Loss: 0.3040, Val Loss: 0.2655
Epoch [20/30], Train Loss: 0.2805, Val Loss: 0.2552
Epoch [30/30], Train Loss: 0.2281, Val Loss: 0.2185
Total Model Running Time: 334.25 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =3, wave_type = haar, mode_type = zero, num_encoder_size=1, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 3 : 0.2105
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =2, wave_type = db1, mode_type = symmetric,num_encoder_size = 1, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 3 
Epoch [10/30], Train Loss: 0.2983, Val Loss: 0.2644
Epoch [20/30], Train Loss: 0.2947, Val Loss: 0.2690
Epoch [30/30], Train Loss: 0.2655, Val Loss: 0.2485
Total Model Running Time: 335.93 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =2, wave_type = db1, mode_type = symmetric, num_encoder_size=1, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 3 : 0.2369
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =3, wave_type = db1, mode_type = symmetric,num_encoder_size = 1, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 3 
Epoch [10/30], Train Loss: 0.3012, Val Loss: 0.2677
Epoch [20/30], Train Loss: 0.3023, Val Loss: 0.2630
Epoch [30/30], Train Loss: 0.2661, Val Loss: 0.2453
Total Model Running Time: 334.23 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =3, wave_type = db1, mode_type = symmetric, num_encoder_size=1, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 3 : 0.2250
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =2, wave_type = haar, mode_type = symmetric,num_encoder_size = 1, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 3 
Epoch [10/30], Train Loss: 0.3048, Val Loss: 0.2802
Epoch [20/30], Train Loss: 0.2637, Val Loss: 0.2475
Epoch [30/30], Train Loss: 0.2239, Val Loss: 0.2183
Total Model Running Time: 339.91 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =2, wave_type = haar, mode_type = symmetric, num_encoder_size=1, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 3 : 0.2009
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =3, wave_type = haar, mode_type = symmetric,num_encoder_size = 1, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 3 
Epoch [10/30], Train Loss: 0.3037, Val Loss: 0.2774
Epoch [20/30], Train Loss: 0.2892, Val Loss: 0.2660
Epoch [30/30], Train Loss: 0.2536, Val Loss: 0.2355
Total Model Running Time: 336.11 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =3, wave_type = haar, mode_type = symmetric, num_encoder_size=1, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 3 : 0.2214
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =2, wave_type = db1, mode_type = zero,num_encoder_size = 3, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 1 
Epoch [10/30], Train Loss: 0.3147, Val Loss: 0.2748
Epoch [20/30], Train Loss: 0.2987, Val Loss: 0.2530
Epoch [30/30], Train Loss: 0.2809, Val Loss: 0.2391
Total Model Running Time: 215.65 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =2, wave_type = db1, mode_type = zero, num_encoder_size=3, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 1 : 0.2198
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =3, wave_type = db1, mode_type = zero,num_encoder_size = 3, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 1 
Epoch [10/30], Train Loss: 0.2999, Val Loss: 0.2536
Epoch [20/30], Train Loss: 0.2795, Val Loss: 0.2344
Epoch [30/30], Train Loss: 0.2356, Val Loss: 0.1989
Total Model Running Time: 215.71 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =3, wave_type = db1, mode_type = zero, num_encoder_size=3, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 1 : 0.1851
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =2, wave_type = haar, mode_type = zero,num_encoder_size = 3, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 1 
Epoch [10/30], Train Loss: 0.3653, Val Loss: 0.3057
Epoch [20/30], Train Loss: 0.3012, Val Loss: 0.2549
Epoch [30/30], Train Loss: 0.2787, Val Loss: 0.2377
Total Model Running Time: 213.14 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =2, wave_type = haar, mode_type = zero, num_encoder_size=3, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 1 : 0.2164
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =3, wave_type = haar, mode_type = zero,num_encoder_size = 3, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 1 
Epoch [10/30], Train Loss: 0.3056, Val Loss: 0.2558
Epoch [20/30], Train Loss: 0.2842, Val Loss: 0.2407
Epoch [30/30], Train Loss: 0.2440, Val Loss: 0.2080
Total Model Running Time: 213.10 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =3, wave_type = haar, mode_type = zero, num_encoder_size=3, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 1 : 0.1944
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =2, wave_type = db1, mode_type = symmetric,num_encoder_size = 3, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 1 
Epoch [10/30], Train Loss: 0.3067, Val Loss: 0.2554
Epoch [20/30], Train Loss: 0.2870, Val Loss: 0.2439
Epoch [30/30], Train Loss: 0.2408, Val Loss: 0.2036
Total Model Running Time: 215.51 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =2, wave_type = db1, mode_type = symmetric, num_encoder_size=3, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 1 : 0.1906
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =3, wave_type = db1, mode_type = symmetric,num_encoder_size = 3, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 1 
Epoch [10/30], Train Loss: 0.3664, Val Loss: 0.3123
Epoch [20/30], Train Loss: 0.2918, Val Loss: 0.2474
Epoch [30/30], Train Loss: 0.2505, Val Loss: 0.2114
Total Model Running Time: 216.06 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =3, wave_type = db1, mode_type = symmetric, num_encoder_size=3, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 1 : 0.1961
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =2, wave_type = haar, mode_type = symmetric,num_encoder_size = 3, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 1 
Epoch [10/30], Train Loss: 0.3080, Val Loss: 0.2668
Epoch [20/30], Train Loss: 0.2875, Val Loss: 0.2455
Epoch [30/30], Train Loss: 0.2494, Val Loss: 0.2203
Total Model Running Time: 218.08 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =2, wave_type = haar, mode_type = symmetric, num_encoder_size=3, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 1 : 0.2032
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =3, wave_type = haar, mode_type = symmetric,num_encoder_size = 3, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 1 
Epoch [10/30], Train Loss: 0.2963, Val Loss: 0.2499
Epoch [20/30], Train Loss: 0.2778, Val Loss: 0.2347
Epoch [30/30], Train Loss: 0.2402, Val Loss: 0.2047
Total Model Running Time: 220.20 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =3, wave_type = haar, mode_type = symmetric, num_encoder_size=3, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 1 : 0.1915
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =2, wave_type = db1, mode_type = zero,num_encoder_size = 3, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 3 
Epoch [10/30], Train Loss: 0.2993, Val Loss: 0.2614
Epoch [20/30], Train Loss: 0.3094, Val Loss: 0.2801
Early stopping triggered
Total Model Running Time: 240.24 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =2, wave_type = db1, mode_type = zero, num_encoder_size=3, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 3 : 0.2542
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =3, wave_type = db1, mode_type = zero,num_encoder_size = 3, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 3 
Epoch [10/30], Train Loss: 0.2984, Val Loss: 0.2598
Epoch [20/30], Train Loss: 0.2903, Val Loss: 0.2569
Epoch [30/30], Train Loss: 0.2942, Val Loss: 0.2606
Early stopping triggered
Total Model Running Time: 329.76 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =3, wave_type = db1, mode_type = zero, num_encoder_size=3, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 3 : 0.2495
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =2, wave_type = haar, mode_type = zero,num_encoder_size = 3, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 3 
Epoch [10/30], Train Loss: 0.2979, Val Loss: 0.2591
Early stopping triggered
Total Model Running Time: 209.20 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =2, wave_type = haar, mode_type = zero, num_encoder_size=3, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 3 : 0.2514
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =3, wave_type = haar, mode_type = zero,num_encoder_size = 3, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 3 
Epoch [10/30], Train Loss: 0.2964, Val Loss: 0.2590
Epoch [20/30], Train Loss: 0.2994, Val Loss: 0.2688
Early stopping triggered
Total Model Running Time: 218.55 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =3, wave_type = haar, mode_type = zero, num_encoder_size=3, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 3 : 0.2532
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =2, wave_type = db1, mode_type = symmetric,num_encoder_size = 3, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 3 
Epoch [10/30], Train Loss: 0.3007, Val Loss: 0.2587
Epoch [20/30], Train Loss: 0.2874, Val Loss: 0.2614
Epoch [30/30], Train Loss: 0.2571, Val Loss: 0.2349
Total Model Running Time: 336.59 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =2, wave_type = db1, mode_type = symmetric, num_encoder_size=3, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 3 : 0.2217
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =3, wave_type = db1, mode_type = symmetric,num_encoder_size = 3, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 3 
Epoch [10/30], Train Loss: 0.2955, Val Loss: 0.2589
Epoch [20/30], Train Loss: 0.2939, Val Loss: 0.2563
Epoch [30/30], Train Loss: 0.2832, Val Loss: 0.2518
Total Model Running Time: 331.03 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =3, wave_type = db1, mode_type = symmetric, num_encoder_size=3, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 3 : 0.2426
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =2, wave_type = haar, mode_type = symmetric,num_encoder_size = 3, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 3 
Epoch [10/30], Train Loss: 0.3045, Val Loss: 0.2621
Epoch [20/30], Train Loss: 0.3040, Val Loss: 0.2686
Early stopping triggered
Total Model Running Time: 266.51 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =2, wave_type = haar, mode_type = symmetric, num_encoder_size=3, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 3 : 0.2533
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =3, wave_type = haar, mode_type = symmetric,num_encoder_size = 3, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 3 
Epoch [10/30], Train Loss: 0.3028, Val Loss: 0.2602
Epoch [20/30], Train Loss: 0.3103, Val Loss: 0.2667
Early stopping triggered
Total Model Running Time: 274.48 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =3, wave_type = haar, mode_type = symmetric, num_encoder_size=3, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 3, decompose_layer = 3 : 0.2517
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =2, wave_type = db1, mode_type = zero,num_encoder_size = 3, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 1 
Epoch [10/30], Train Loss: 0.3026, Val Loss: 0.2562
Epoch [20/30], Train Loss: 0.2882, Val Loss: 0.2434
Epoch [30/30], Train Loss: 0.2416, Val Loss: 0.2304
Total Model Running Time: 251.64 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =2, wave_type = db1, mode_type = zero, num_encoder_size=3, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 1 : 0.1933
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =3, wave_type = db1, mode_type = zero,num_encoder_size = 3, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 1 
Epoch [10/30], Train Loss: 0.2932, Val Loss: 0.2469
Epoch [20/30], Train Loss: 0.2517, Val Loss: 0.2121
Epoch [30/30], Train Loss: 0.2360, Val Loss: 0.1973
Total Model Running Time: 252.75 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =3, wave_type = db1, mode_type = zero, num_encoder_size=3, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 1 : 0.1840
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =2, wave_type = haar, mode_type = zero,num_encoder_size = 3, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 1 
Epoch [10/30], Train Loss: 0.2940, Val Loss: 0.2471
Epoch [20/30], Train Loss: 0.2925, Val Loss: 0.2463
Epoch [30/30], Train Loss: 0.2427, Val Loss: 0.2044
Total Model Running Time: 250.71 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =2, wave_type = haar, mode_type = zero, num_encoder_size=3, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 1 : 0.1914
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =3, wave_type = haar, mode_type = zero,num_encoder_size = 3, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 1 
Epoch [10/30], Train Loss: 0.2976, Val Loss: 0.2591
Epoch [20/30], Train Loss: 0.2813, Val Loss: 0.2359
Epoch [30/30], Train Loss: 0.2391, Val Loss: 0.2008
Total Model Running Time: 250.45 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =3, wave_type = haar, mode_type = zero, num_encoder_size=3, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 1 : 0.1886
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =2, wave_type = db1, mode_type = symmetric,num_encoder_size = 3, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 1 
Epoch [10/30], Train Loss: 0.2993, Val Loss: 0.2515
Epoch [20/30], Train Loss: 0.2581, Val Loss: 0.2148
Epoch [30/30], Train Loss: 0.2339, Val Loss: 0.1985
Total Model Running Time: 252.68 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =2, wave_type = db1, mode_type = symmetric, num_encoder_size=3, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 1 : 0.1851
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =3, wave_type = db1, mode_type = symmetric,num_encoder_size = 3, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 1 
Epoch [10/30], Train Loss: 0.3164, Val Loss: 0.2704
Epoch [20/30], Train Loss: 0.2881, Val Loss: 0.2426
Epoch [30/30], Train Loss: 0.2483, Val Loss: 0.2069
Total Model Running Time: 249.30 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =3, wave_type = db1, mode_type = symmetric, num_encoder_size=3, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 1 : 0.1936
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =2, wave_type = haar, mode_type = symmetric,num_encoder_size = 3, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 1 
Epoch [10/30], Train Loss: 0.3017, Val Loss: 0.2550
Epoch [20/30], Train Loss: 0.2901, Val Loss: 0.2459
Epoch [30/30], Train Loss: 0.2597, Val Loss: 0.2151
Total Model Running Time: 252.01 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =2, wave_type = haar, mode_type = symmetric, num_encoder_size=3, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 1 : 0.2012
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =3, wave_type = haar, mode_type = symmetric,num_encoder_size = 3, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 1 
Epoch [10/30], Train Loss: 0.2931, Val Loss: 0.2472
Epoch [20/30], Train Loss: 0.2444, Val Loss: 0.2039
Epoch [30/30], Train Loss: 0.2289, Val Loss: 0.1933
Total Model Running Time: 255.11 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =3, wave_type = haar, mode_type = symmetric, num_encoder_size=3, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 1 : 0.1807
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =2, wave_type = db1, mode_type = zero,num_encoder_size = 3, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 3 
Epoch [10/30], Train Loss: 0.2969, Val Loss: 0.2575
Epoch [20/30], Train Loss: 0.2945, Val Loss: 0.2571
Early stopping triggered
Total Model Running Time: 334.19 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =2, wave_type = db1, mode_type = zero, num_encoder_size=3, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 3 : 0.2522
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =3, wave_type = db1, mode_type = zero,num_encoder_size = 3, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 3 
Epoch [10/30], Train Loss: 0.3049, Val Loss: 0.2634
Epoch [20/30], Train Loss: 0.3117, Val Loss: 0.2805
Early stopping triggered
Total Model Running Time: 305.86 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =3, wave_type = db1, mode_type = zero, num_encoder_size=3, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 3 : 0.2452
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =2, wave_type = haar, mode_type = zero,num_encoder_size = 3, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 3 
Epoch [10/30], Train Loss: 0.3650, Val Loss: 0.3129
Early stopping triggered
Total Model Running Time: 195.19 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =2, wave_type = haar, mode_type = zero, num_encoder_size=3, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 3 : 0.2550
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =3, wave_type = haar, mode_type = zero,num_encoder_size = 3, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 3 
Epoch [10/30], Train Loss: 0.2970, Val Loss: 0.2658
Epoch [20/30], Train Loss: 0.2888, Val Loss: 0.2598
Epoch [30/30], Train Loss: 0.2795, Val Loss: 0.2524
Total Model Running Time: 368.16 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =3, wave_type = haar, mode_type = zero, num_encoder_size=3, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 3 : 0.2510
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =2, wave_type = db1, mode_type = symmetric,num_encoder_size = 3, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 3 
Epoch [10/30], Train Loss: 0.3055, Val Loss: 0.2709
Epoch [20/30], Train Loss: 0.2914, Val Loss: 0.2593
Epoch [30/30], Train Loss: 0.2824, Val Loss: 0.2558
Total Model Running Time: 372.26 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =2, wave_type = db1, mode_type = symmetric, num_encoder_size=3, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 3 : 0.2408
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =3, wave_type = db1, mode_type = symmetric,num_encoder_size = 3, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 3 
Epoch [10/30], Train Loss: 0.2931, Val Loss: 0.2671
Early stopping triggered
Total Model Running Time: 239.47 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =3, wave_type = db1, mode_type = symmetric, num_encoder_size=3, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 3 : 0.2531
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =2, wave_type = haar, mode_type = symmetric,num_encoder_size = 3, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 3 
Epoch [10/30], Train Loss: 0.3192, Val Loss: 0.2966
Epoch [20/30], Train Loss: 0.2887, Val Loss: 0.2570
Early stopping triggered
Total Model Running Time: 302.96 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =2, wave_type = haar, mode_type = symmetric, num_encoder_size=3, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 3 : 0.2443
Running experiment with Data_load_type = multivariate, TCN_type=dilated2, attention_type=original,dilations =3, wave_type = haar, mode_type = symmetric,num_encoder_size = 3, mlp_hidden_size = 128,skip_enabled=True, general_skip=skip, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 3 
Epoch [10/30], Train Loss: 0.2963, Val Loss: 0.2553
Epoch [20/30], Train Loss: 0.2865, Val Loss: 0.2528
Epoch [30/30], Train Loss: 0.2522, Val Loss: 0.2335
Total Model Running Time: 381.76 seconds
Test Loss for configuration: TCN_type=dilated2, attention_type=original,dilations =3, wave_type = haar, mode_type = symmetric, num_encoder_size=3, mlp_hidden_size = 128, skip_enabled=True, general_skip=skip, Data Load Type=multivariate, Pos_Encoder_Type = Projected, batch_size = 64, step_size = 16, kernel_size = 5, decompose_layer = 3 : 0.2206
