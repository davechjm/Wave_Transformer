/var/spool/slurm/d/job633749/slurm_script: line 9: cd: too many arguments
Traceback (most recent call last):
  File "New2.py", line 941, in <module>
    best_model.load_state_dict(torch.load(best_model_path))
  File "/home/choi/conda/anaconda3/envs/pytorchenv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 2041, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for DWT_MLP_Model:
	Missing key(s) in state_dict: "reduce.reduction_layer.weight", "reduce.reduction_layer.bias", "transformer.W_pos", "transformer.W_P.weight", "transformer.W_P.bias", "transformer.encoder.layers.0.self_attn.W_Q.weight", "transformer.encoder.layers.0.self_attn.W_Q.bias", "transformer.encoder.layers.0.self_attn.W_K.weight", "transformer.encoder.layers.0.self_attn.W_K.bias", "transformer.encoder.layers.0.self_attn.W_V.weight", "transformer.encoder.layers.0.self_attn.W_V.bias", "transformer.encoder.layers.0.self_attn.sdp_attn.scale", "transformer.encoder.layers.0.self_attn.to_out.0.weight", "transformer.encoder.layers.0.self_attn.to_out.0.bias", "transformer.encoder.layers.0.norm_attn.1.weight", "transformer.encoder.layers.0.norm_attn.1.bias", "transformer.encoder.layers.0.norm_attn.1.running_mean", "transformer.encoder.layers.0.norm_attn.1.running_var", "transformer.encoder.layers.0.ff.0.weight", "transformer.encoder.layers.0.ff.0.bias", "transformer.encoder.layers.0.ff.3.weight", "transformer.encoder.layers.0.ff.3.bias", "transformer.encoder.layers.0.norm_ffn.1.weight", "transformer.encoder.layers.0.norm_ffn.1.bias", "transformer.encoder.layers.0.norm_ffn.1.running_mean", "transformer.encoder.layers.0.norm_ffn.1.running_var", "head.linear.weight", "head.linear.bias". 
	Unexpected key(s) in state_dict: "transformer_low.W_pos", "transformer_low.W_P.weight", "transformer_low.W_P.bias", "transformer_low.encoder.layers.0.self_attn.W_Q.weight", "transformer_low.encoder.layers.0.self_attn.W_Q.bias", "transformer_low.encoder.layers.0.self_attn.W_K.weight", "transformer_low.encoder.layers.0.self_attn.W_K.bias", "transformer_low.encoder.layers.0.self_attn.W_V.weight", "transformer_low.encoder.layers.0.self_attn.W_V.bias", "transformer_low.encoder.layers.0.self_attn.sdp_attn.scale", "transformer_low.encoder.layers.0.self_attn.to_out.0.weight", "transformer_low.encoder.layers.0.self_attn.to_out.0.bias", "transformer_low.encoder.layers.0.norm_attn.1.weight", "transformer_low.encoder.layers.0.norm_attn.1.bias", "transformer_low.encoder.layers.0.norm_attn.1.running_mean", "transformer_low.encoder.layers.0.norm_attn.1.running_var", "transformer_low.encoder.layers.0.norm_attn.1.num_batches_tracked", "transformer_low.encoder.layers.0.ff.0.weight", "transformer_low.encoder.layers.0.ff.0.bias", "transformer_low.encoder.layers.0.ff.3.weight", "transformer_low.encoder.layers.0.ff.3.bias", "transformer_low.encoder.layers.0.norm_ffn.1.weight", "transformer_low.encoder.layers.0.norm_ffn.1.bias", "transformer_low.encoder.layers.0.norm_ffn.1.running_mean", "transformer_low.encoder.layers.0.norm_ffn.1.running_var", "transformer_low.encoder.layers.0.norm_ffn.1.num_batches_tracked". 
	size mismatch for transformer_high_list.0.W_pos: copying a param with shape torch.Size([13, 325]) from checkpoint, the shape in current model is torch.Size([22, 325]).
	size mismatch for transformer_high_list.0.W_P.weight: copying a param with shape torch.Size([325, 4]) from checkpoint, the shape in current model is torch.Size([325, 16]).
	size mismatch for head_low.linear.weight: copying a param with shape torch.Size([48, 4225]) from checkpoint, the shape in current model is torch.Size([8, 7150]).
	size mismatch for head_low.linear.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([8]).
	size mismatch for head_high.0.linear.weight: copying a param with shape torch.Size([48, 4225]) from checkpoint, the shape in current model is torch.Size([8, 7150]).
	size mismatch for head_high.0.linear.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([8]).
srun: error: gpu-011: task 0: Exited with exit code 1
