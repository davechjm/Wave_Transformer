{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 606\u001b[0m\n\u001b[1;32m    603\u001b[0m inputs \u001b[38;5;241m=\u001b[39m seq_x\n\u001b[1;32m    605\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 606\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Model must be adjusted to handle input shape [batch, seq_len, 1]\u001b[39;00m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;66;03m# Calculate loss\u001b[39;00m\n\u001b[1;32m    609\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, seq_y)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 497\u001b[0m, in \u001b[0;36mModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;66;03m# Pass input through the backbone model\u001b[39;00m\n\u001b[1;32m    496\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackbone_res(res)\n\u001b[0;32m--> 497\u001b[0m trend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackbone_trend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    498\u001b[0m x \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m+\u001b[39mtrend\n\u001b[1;32m    500\u001b[0m \u001b[38;5;66;03m# Further processing and pass through the final layer\u001b[39;00m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;66;03m#x = x.reshape(x.shape[0], x.shape[1], -1)  # Flatten if necessary\u001b[39;00m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;66;03m#output = self.final_layer(x)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 464\u001b[0m, in \u001b[0;36mDWT_MLP_Model.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    460\u001b[0m x_high_combined \u001b[38;5;241m=\u001b[39m x_high \u001b[38;5;241m+\u001b[39m x_high_combined\n\u001b[1;32m    462\u001b[0m x_high_combined \u001b[38;5;241m=\u001b[39m x_high_combined\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 464\u001b[0m x_high_combined \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_high_combined\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    465\u001b[0m x_high_combined, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer_high_list[i](x_high_combined)  \u001b[38;5;66;03m# Adjusted for custom encoder\u001b[39;00m\n\u001b[1;32m    466\u001b[0m x_high_combined \u001b[38;5;241m=\u001b[39m x_high\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m x_high_combined\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 249\u001b[0m, in \u001b[0;36mProjectedPositionalEncoding.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    247\u001b[0m x_projected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprojection(x)\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# Add positional encoding\u001b[39;00m\n\u001b[0;32m--> 249\u001b[0m x_pe \u001b[38;5;241m=\u001b[39m x_projected \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpositionalencoding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x_pe\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 229\u001b[0m, in \u001b[0;36mPositionalEncoding.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    228\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpe[:x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), :]\n\u001b[0;32m--> 229\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py:59\u001b[0m, in \u001b[0;36mDropout.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/functional.py:1268\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[1;32m   1267\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1268\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# %%\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GATConv\n",
    "from torch_scatter import scatter_add, scatter_max\n",
    "from pytorch_wavelets import DWT1DForward, DWT1DInverse\n",
    "import warnings\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Optional\n",
    "from torch_geometric.utils import to_dense_adj, dense_to_sparse\n",
    "from torch.nn import Sequential, LayerNorm, ReLU\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "from torch.nn import Linear, Parameter\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.nn.inits import glorot, zeros\n",
    "from torch_geometric.utils import add_self_loops, remove_self_loops, softmax\n",
    "from torch.utils.data import random_split\n",
    "from torch.nn import InstanceNorm1d\n",
    "from torch import Tensor\n",
    "\n",
    "import optuna\n",
    "\n",
    "from RevIN import RevIN\n",
    "\n",
    "    \n",
    "class Dataset_Custom(Dataset):\n",
    "    def __init__(self, root_path, flag='train', size=None,\n",
    "                 features='M', data_path='ETTh1.csv',\n",
    "                 target='OT', scale=True, timeenc=0, freq='h',step_size=1):\n",
    "        # Initialize with seq_len and pred_len only\n",
    "        if size is None:\n",
    "            self.seq_len = 96  # Default value, can be adjusted\n",
    "            self.pred_len = 96  # Default value, can be adjusted\n",
    "        else:\n",
    "            self.seq_len, self.pred_len = size[:2]\n",
    "            \n",
    "        \n",
    "        \n",
    "        assert flag in ['train', 'test', 'val']\n",
    "        self.set_type = {'train': 0, 'val': 1, 'test': 2}[flag]\n",
    "\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "        self.scale = scale\n",
    "        self.timeenc = timeenc\n",
    "        self.freq = freq\n",
    "        self.step_size = step_size\n",
    "\n",
    "        self.root_path = root_path\n",
    "        self.data_path = data_path\n",
    "        self.__read_data__()\n",
    "\n",
    "    def __read_data__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "        df_raw = pd.read_csv(os.path.join(self.root_path, self.data_path))\n",
    "        \n",
    "        cols_data = [col for col in df_raw.columns if col != 'date']\n",
    "        df_data = df_raw[cols_data]\n",
    "        \n",
    "        num_train = int(len(df_raw) * 0.6)\n",
    "        num_test = int(len(df_raw) * 0.2)\n",
    "        border1s = [0, num_train - self.seq_len, len(df_raw) - num_test - self.seq_len]\n",
    "        border2s = [num_train, num_train + (len(df_raw) - num_train - num_test), len(df_raw)]\n",
    "        border1 = border1s[self.set_type]\n",
    "        border2 = border2s[self.set_type]\n",
    "        \n",
    "        if self.features == 'M' or self.features == 'MS':\n",
    "            pass\n",
    "        elif self.features == 'S':\n",
    "            cols_data = df_raw.columns[1:]  # Assuming the first column is 'date' and should be excluded\n",
    "            self.feature_datasets = {}\n",
    "            for col in cols_data:\n",
    "                feature_data = df_raw[[col]]\n",
    "                if self.scale:\n",
    "                    self.scaler.fit(feature_data)\n",
    "                    feature_data = self.scaler.transform(feature_data)\n",
    "                self.feature_datasets[col] = feature_data\n",
    "        \n",
    "        if self.scale:\n",
    "            train_data = df_data.iloc[border1s[0]:border2s[0]].values\n",
    "            self.scaler.fit(train_data)\n",
    "            data = self.scaler.transform(df_data.values)\n",
    "        else:\n",
    "            data = df_data.values\n",
    "        \n",
    "        df_stamp = df_raw[['date']].iloc[border1:border2]\n",
    "        df_stamp['date'] = pd.to_datetime(df_stamp['date'])\n",
    "        if self.timeenc == 0:\n",
    "            df_stamp['month'] = df_stamp['date'].dt.month\n",
    "            df_stamp['day'] = df_stamp['date'].dt.day\n",
    "            df_stamp['weekday'] = df_stamp['date'].dt.weekday\n",
    "            df_stamp['hour'] = df_stamp['date'].dt.hour\n",
    "            data_stamp = df_stamp.drop(['date'], axis=1).values\n",
    "        elif self.timeenc == 1:\n",
    "            # Example for time_features function\n",
    "            data_stamp = self.time_features(df_stamp['date'], freq=self.freq)\n",
    "\n",
    "        self.data_x = data[border1:border2 - self.pred_len]\n",
    "        self.data_y = data[border1 + self.seq_len:border2]\n",
    "        self.data_stamp = data_stamp\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Calculate the actual start index based on the step size\n",
    "        actual_start_index = index * self.step_size\n",
    "\n",
    "        seq_x = self.data_x[actual_start_index:actual_start_index + self.seq_len]\n",
    "        seq_y = self.data_y[actual_start_index:actual_start_index + self.pred_len]\n",
    "        seq_x_mark = self.data_stamp[actual_start_index:actual_start_index + self.seq_len]\n",
    "        seq_y_mark = self.data_stamp[actual_start_index:actual_start_index + self.pred_len]\n",
    "\n",
    "        return torch.tensor(seq_x,  dtype=torch.float32), torch.tensor(seq_y,  dtype=torch.float32), torch.tensor(seq_x_mark,  dtype=torch.float32), torch.tensor(seq_y_mark,  dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        # Adjust the total length to account for the step size\n",
    "        total_steps = (len(self.data_x) - self.seq_len - self.pred_len + 1) // self.step_size\n",
    "        return total_steps\n",
    "\n",
    "\n",
    "    def inverse_transform(self, data):\n",
    "        return self.scaler.inverse_transform(data)\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "def sparse_attention(self, q, k, v, key_padding_mask=None, attn_mask=None):\n",
    "    bs, n_heads, seq_len, d_k = q.size()\n",
    "    attn_scores = torch.matmul(q, k.transpose(-2, -1)) / np.sqrt(d_k)\n",
    "\n",
    "    # Correct handling of top-k + log-space indices\n",
    "    topk_scores, topk_indices = attn_scores.topk(self.k_neighbors, dim=-1)\n",
    "\n",
    "    # Ensure proper dimensionality for combined indices\n",
    "    log_space_indices = torch.logspace(0, np.log10(seq_len-1), steps=self.k_neighbors, base=10).long()\n",
    "    log_space_indices = log_space_indices[None, None, :].expand(bs, n_heads, -1)  # Expand dims to match\n",
    "    combined_indices = torch.cat((topk_indices, log_space_indices), dim=-1)\n",
    "    combined_indices = combined_indices.unique(sorted=True)\n",
    "\n",
    "    # Filtering needs to adjust to correct tensor shapes\n",
    "    attn_scores_filtered = torch.full_like(attn_scores, float('-inf'))\n",
    "    attn_scores_filtered.scatter_(-1, combined_indices.unsqueeze(-1).expand(-1, -1, -1, seq_len), attn_scores.gather(-1, combined_indices.unsqueeze(-1).expand(-1, -1, -1, seq_len)))\n",
    "\n",
    "    if attn_mask is not None:\n",
    "        attn_scores_filtered = attn_scores_filtered.masked_fill(attn_mask == 0, float('-inf'))\n",
    "    \n",
    "    attn_weights = F.softmax(attn_scores_filtered, dim=-1)\n",
    "    attn_weights = self.attn_dropout(attn_weights)\n",
    "\n",
    "    output = torch.matmul(attn_weights, v)\n",
    "\n",
    "    return output, attn_weights\n",
    "\n",
    "class DilatedTCNBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, dilation=1, dropout_rate=0.2, dropout_=True, skip_=True):\n",
    "        super(DilatedTCNBlock, self).__init__()\n",
    "        \n",
    "        # Calculate padding based on kernel size and dilation to maintain input length\n",
    "        padding = (dilation * (kernel_size - 1)) // 2\n",
    "        \n",
    "        # First convolutional layer\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, padding=padding, dilation=dilation)\n",
    "        self.norm1 = InstanceNorm1d(out_channels)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout_rate) if dropout_ else nn.Identity()\n",
    "\n",
    "        # Second convolutional layer\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size, padding=padding, dilation=dilation)\n",
    "        self.norm2 = InstanceNorm1d(out_channels)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout_rate) if dropout_ else nn.Identity()\n",
    "\n",
    "        self.skip_ = skip_\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_original = x.clone()\n",
    "        \n",
    "        # First conv -> norm -> relu -> dropout\n",
    "        x = self.conv1(x)\n",
    "        x = self.norm1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        # Second conv -> norm -> relu -> dropout\n",
    "        x = self.conv2(x)\n",
    "        x = self.norm2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        if self.skip_:\n",
    "            x = x + x_original\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "# %%\n",
    "# Take the new Positinal Encoding and Project layer from PatchTST\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        if d_model%2 != 0:\n",
    "            pe[:, 1::2] = torch.cos(position * div_term)[:,0:-1]\n",
    "        else:\n",
    "            pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "    \n",
    "\n",
    "\n",
    "class ProjectedPositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_input, d_model, dropout=0.1, max_len=5000):\n",
    "        super(ProjectedPositionalEncoding, self).__init__()\n",
    "        self.d_input = d_input\n",
    "        self.d_model = d_model\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        # Projection layer: maps input dimension to model dimension\n",
    "        self.projection = nn.Linear(d_input, d_model)\n",
    "\n",
    "        self.positionalencoding = PositionalEncoding(d_model,dropout, max_len = 5000)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply linear projection\n",
    "        x_projected = self.projection(x)\n",
    "        # Add positional encoding\n",
    "        x_pe = x_projected + self.positionalencoding(x)\n",
    "        return x_pe\n",
    "\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, attention, d_model,d_ff=None, dropout=0.1, activation=\"relu\"):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        d_ff = d_ff or 4 * d_model\n",
    "        self.attention = attention\n",
    "        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = F.relu if activation == \"relu\" else F.gelu\n",
    "\n",
    "    def forward(self, x):\n",
    "        new_x, attn = self.attention(\n",
    "            x, x, x\n",
    "        )\n",
    "        x = x + self.dropout(new_x)\n",
    "\n",
    "        y = x = self.norm1(x)\n",
    "        y = self.dropout(self.activation(self.conv1(y.transpose(-1, 1))))\n",
    "        y = self.dropout(self.conv2(y).transpose(-1, 1))\n",
    "\n",
    "        return self.norm2(x + y), attn\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, attn_layers, conv_layers=None, norm_layer=None):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.attn_layers = nn.ModuleList(attn_layers)\n",
    "        self.conv_layers = nn.ModuleList(conv_layers) if conv_layers is not None else None\n",
    "        self.norm = norm_layer\n",
    "\n",
    "    def forward(self, x, attn_mask=None):\n",
    "        # x [B, L, D]\n",
    "        attns = []\n",
    "        if self.conv_layers is not None:\n",
    "            for attn_layer, conv_layer in zip(self.attn_layers, self.conv_layers):\n",
    "                x, attn = attn_layer(x, attn_mask=attn_mask)\n",
    "                x = conv_layer(x)\n",
    "                attns.append(attn)\n",
    "            x, attn = self.attn_layers[-1](x)\n",
    "            attns.append(attn)\n",
    "        else:\n",
    "            for attn_layer in self.attn_layers:\n",
    "                x, attn = attn_layer(x)\n",
    "                attns.append(attn)\n",
    "\n",
    "        if self.norm is not None:\n",
    "            x = self.norm(x)\n",
    "\n",
    "        return x, attns\n",
    "\n",
    "\n",
    "# %%\n",
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    d_k = query.size(-1)\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, float('-inf'))\n",
    "\n",
    "    p_attn = torch.softmax(scores, dim=-1)\n",
    "\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "\n",
    "    return torch.matmul(p_attn, value), p_attn\n",
    "\n",
    "\n",
    "class moving_avg(nn.Module):\n",
    "    \"\"\"\n",
    "    Moving average block to highlight the trend of time series\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_size, stride):\n",
    "        super(moving_avg, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.avg = nn.AvgPool1d(kernel_size=kernel_size, stride=stride, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # padding on the both ends of time series\n",
    "        front = x[:, 0:1, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
    "        end = x[:, -1:, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
    "        x = torch.cat([front, x, end], dim=1)\n",
    "        x = self.avg(x.permute(0, 2, 1))\n",
    "        x = x.permute(0, 2, 1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class series_decomp(nn.Module):\n",
    "    \"\"\"\n",
    "    Series decomposition block\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_size):\n",
    "        super(series_decomp, self).__init__()\n",
    "        self.moving_avg = moving_avg(kernel_size, stride=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        moving_mean = self.moving_avg(x)\n",
    "        res = x - moving_mean\n",
    "        return res, moving_mean\n",
    "    \n",
    "\n",
    "# %%\n",
    "# What removed: TCN_type, attention_type, general_skip, RevIN\n",
    "class DWT_MLP_Model(nn.Module):\n",
    "    def __init__(self, input_channels, seq_length, pred_length ,mlp_hidden_size, output_channels, decompose_layers=3, wave='haar', mode='symmetric', nhead=8, d_model=None, num_encoder_layers=3, dropout=0.1, dilation = 2, kernel_size = 3, dropout_ = True, skip_ = True,  pos_encoder_type_ = 'Projected'):\n",
    "        super(DWT_MLP_Model, self).__init__()\n",
    "        self.dwt_forward = DWT1DForward(J=decompose_layers, wave=wave, mode=mode)\n",
    "        self.dwt_inverse = DWT1DInverse(wave=wave, mode=mode)\n",
    "        self.seq_len = seq_length\n",
    "        self.pred_len = pred_length\n",
    "        self.dropout = dropout\n",
    "        self.dilation = dilation\n",
    "        self.kernel_size = kernel_size\n",
    "        self.num_decoder_layers = num_encoder_layers\n",
    "        self.dropout_TF = dropout_\n",
    "        self.skip_TF = skip_\n",
    "        self.pos_encoder_type = pos_encoder_type_\n",
    "        if d_model is None:\n",
    "            d_model = input_channels\n",
    "\n",
    "       \n",
    "        # Assuming kernel_size can be used to derive kernel_set for illustration\n",
    "        self.tcn_low = DilatedTCNBlock(input_channels, output_channels, dilation=self.dilation,kernel_size= self.kernel_size, dropout_rate= self.dropout, dropout_ = self.dropout_TF, skip_ = self.skip_TF)\n",
    "        self.tcn_high_list = nn.ModuleList([DilatedTCNBlock(input_channels, output_channels, dropout_rate= self.dropout, kernel_size= self.kernel_size, dilation= self.dilation) for _ in range(decompose_layers)])\n",
    "\n",
    "        \n",
    "        self.revin_layer = RevIN(input_channels)\n",
    "        \n",
    "        # Positional Encoding\n",
    "        if  self.pos_encoder_type == 'Projected':  \n",
    "            self.pos_encoder = ProjectedPositionalEncoding(input_channels, d_model, max_len=5000)\n",
    "        else:\n",
    "            self.pos_encoder = PositionalEncoding(d_model, max_len = 5000)\n",
    "        # Custom Transformer Encoder setup\n",
    "      \n",
    "        self.attention = attention  # Assuming attention is defined elsewhere\n",
    "        encoder_layers_low = [EncoderLayer(self.attention, d_model, d_ff=mlp_hidden_size, dropout=self.dropout, activation=\"relu\") for _ in range(num_encoder_layers)]\n",
    "        self.transformer_low = Encoder(encoder_layers_low, norm_layer=nn.LayerNorm(d_model))\n",
    "\n",
    "        # Transformer Encoders for high-frequency components, using custom Encoder\n",
    "        self.transformer_high_list = nn.ModuleList(\n",
    "            [Encoder([EncoderLayer(self.attention, d_model, d_ff=mlp_hidden_size, dropout=self.dropout, activation=\"relu\") for _ in range(num_encoder_layers)]) \n",
    "             for _ in range(decompose_layers)])\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = x.permute(0, 2, 1)  # Adjust dimensions for DWT\n",
    "        x = self.revin_layer(x, 'norm')\n",
    "        x = x.permute(0,2,1)\n",
    "\n",
    "\n",
    "        x_low, x_highs = self.dwt_forward(x)\n",
    "        x_low_tcn = self.tcn_low(x_low)\n",
    "        x_low_combined = x_low_tcn\n",
    "        \n",
    "        x_low_combined = x_low + x_low_combined\n",
    "      \n",
    "                \n",
    "        x_low_combined = x_low_combined.permute(0,2,1)\n",
    "    \n",
    "        x_low_combined = self.pos_encoder(x_low_combined)\n",
    "        x_low_combined, _ = self.transformer_low(x_low_combined) # Adjusted for custom encoder\n",
    "        x_low_combined = x_low_combined.permute(0,2,1)\n",
    "        x_low_combined = x_low + x_low_combined\n",
    "\n",
    "        \n",
    "        # Process high-frequency components\n",
    "        x_highs_processed = []\n",
    "        for i, x_high in enumerate(x_highs):\n",
    "            x_high_tcn = self.tcn_high_list[i](x_high)\n",
    "            x_high_combined = x_high_tcn\n",
    "          \n",
    "            x_high_combined = x_high + x_high_combined\n",
    "          \n",
    "            x_high_combined = x_high_combined.permute(0,2,1)\n",
    "         \n",
    "            x_high_combined = self.pos_encoder(x_high_combined)\n",
    "            x_high_combined, _ = self.transformer_high_list[i](x_high_combined)  # Adjusted for custom encoder\n",
    "            x_high_combined = x_high.permute(0,2,1) + x_high_combined\n",
    "            x_highs_processed.append(x_high_combined.permute(0,2,1))\n",
    "\n",
    "            \n",
    "     \n",
    "        # Reconstruct the signal and adjust dimensions\n",
    "        pred_out = self.dwt_inverse((x_low_combined, x_highs_processed)).permute(0, 2, 1)\n",
    "        pred_out = self.revin_layer(pred_out, 'denorm')\n",
    "        \n",
    "        pred_out = pred_out# Do not make predictions for meta features\n",
    "        pred_out = pred_out[:, -self.pred_len:, :]\n",
    "\n",
    "\n",
    "        return pred_out\n",
    "    \n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_channels, seq_length, pred_length, mlp_hidden_size, output_channels, decompose_layers=3, wave='haar', mode='symmetric', nhead=8, d_model=None, num_encoder_layers=3, dropout=0.1, dilation=2, kernel_size=3, dropout_=True, skip_=True, pos_encoder_type_='Projected', final_output_channels=None):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.series_decompose = series_decomp(kernel_size =25)\n",
    "        # Initialize the backbone model with the specified parameters\n",
    "        self.backbone = DWT_MLP_Model(input_channels, seq_length, pred_length, mlp_hidden_size, output_channels, decompose_layers, wave, mode, nhead, d_model, num_encoder_layers, dropout, dilation, kernel_size, dropout_, skip_, pos_encoder_type_)\n",
    "        #self.backbone_res = DWT_MLP_Model(input_channels, seq_length, pred_length, mlp_hidden_size, output_channels, decompose_layers, wave, mode, nhead, d_model, num_encoder_layers, dropout, dilation, kernel_size, dropout_, skip_, pos_encoder_type_)\n",
    "        \n",
    "       \n",
    "    \n",
    "    def forward(self, x):\n",
    "        #res,trend = self.series_decompose(x)\n",
    "        # Pass input through the backbone model\n",
    "        x = self.backbone(x)\n",
    "        \n",
    "        # Further processing and pass through the final layer\n",
    "        #x = x.reshape(x.shape[0], x.shape[1], -1)  # Flatten if necessary\n",
    "        #output = self.final_layer(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "seq_ = 24*4\n",
    "pred_ = 24*4\n",
    "# Define hyperparameter combinations\n",
    "dropout_enabled = True\n",
    "skip_enabled = True\n",
    "num_encoder_size = 1\n",
    "pos_encoder_type = 'Projected'\n",
    "mlp_hidden = 128\n",
    "k_size = 5\n",
    "s_size = 8\n",
    "decompose_layer = 1\n",
    "bs = 8\n",
    "mt = 'zero'\n",
    "wt = 'haar'\n",
    "dilat = 3\n",
    "# Define the ranges for the hyperparameters\n",
    "learning_rates = np.logspace(-3, -2, 100)  # Learning rates between 1e-3 and 1e-2\n",
    "dropout_rates = np.linspace(0.0, 0.2, 100)  # Dropout rates between 0 and 0.5\n",
    "weight_decays = np.logspace(-4, -3, 100)  # Weight decays between 1e-4 and 1e-3\n",
    "indices = [0,1,2,3,4,5] #np.random.choice(range(100), size=3, replace=False)\n",
    "input_length = [24*4, 512]\n",
    "\n",
    "count = 0\n",
    "\n",
    "for i in indices:\n",
    "    if i < 3:\n",
    "        seq_length = input_length[0]\n",
    "    else:\n",
    "        seq_length = input_length[1]\n",
    "    #lrs = learning_rates[i]\n",
    "    #dr = dropout_rates[i]\n",
    "    #wd = weight_decays[i]\n",
    "    lrs =0.0052230056036904522\n",
    "    dr = 0.10146011891748014\n",
    "    wd = 1.0059977697794999e-04\n",
    "                                              \n",
    "    # Specify the file path\n",
    "    root_path = '/home/choi/Wave_Transformer/optuna_/electricity/'\n",
    "    data_path = 'electricity.csv'\n",
    "    # Size parameters\n",
    "\n",
    "    seq_len = seq_length # 24*4*4\n",
    "    pred_len = 24*4\n",
    "    #batch_size = bs\n",
    "    # Initialize the custom dataset for training, validation, and testing\n",
    "    train_dataset = Dataset_Custom(root_path=root_path, features= 'M', flag='train', data_path=data_path, step_size =s_size)\n",
    "    val_dataset = Dataset_Custom(root_path=root_path, features= 'M',flag='val', data_path=data_path,step_size = s_size)\n",
    "    test_dataset = Dataset_Custom(root_path=root_path, features= 'M',flag='test', data_path=data_path,step_size = s_size)\n",
    "\n",
    "    # Optionally, initialize the dataset for prediction (if needed)\n",
    "    #pred_dataset = Dataset_Pred(root_path=root_path, flag='pred', size=size, data_path=data_path, inverse=True)\n",
    "\n",
    "    # Example on how to create DataLoaders for PyTorch training (adjust batch_size as needed)\n",
    "    batch_size = bs\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last = True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, drop_last = True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last = False)\n",
    "    dropout_rate = dr if dropout_enabled else 0.0\n",
    "    # Adjust the model instantiation to include all hyperparameters\n",
    "    model = Model(input_channels=321, seq_length=seq_len, pred_length = pred_,mlp_hidden_size=mlp_hidden, \n",
    "                        output_channels=321, decompose_layers=decompose_layer, \n",
    "                        dropout=dropout_rate, dilation=dilat, \n",
    "                        mode=mt, wave=wt, kernel_size=k_size, \n",
    "                        num_encoder_layers=num_encoder_size, nhead=8, \n",
    "                        dropout_=dropout_enabled,\n",
    "                        skip_=True, pos_encoder_type_ = pos_encoder_type)\n",
    "    \n",
    "\n",
    "\n",
    "    # Define criterion and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lrs, \n",
    "                        weight_decay=wd)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    # Early stopping parameters\n",
    "    patience = 10\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    num_epochs = 50\n",
    "\n",
    "    # Start the timer\n",
    "    start_time = time.time()\n",
    "\n",
    "    best_model_path = f\"best_model_haar200_{i}_{num_encoder_size}_{skip_enabled}_{pos_encoder_type}_{bs}_{decompose_layer}_{k_size}_{s_size}_{mlp_hidden}.pt\"\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for seq_x, seq_y, seq_x_mark, seq_y_mark in train_loader:\n",
    "            inputs = seq_x\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)  # Model must be adjusted to handle input shape [batch, seq_len, 1]\n",
    "           \n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, seq_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * bs\n",
    "          \n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for seq_x, seq_y, seq_x_mark, seq_y_mark in val_loader:\n",
    "                inputs = seq_x\n",
    "                outputs = model(inputs)  # Model must be adjusted to handle input shape [batch, seq_len, 1]\n",
    "                # Calculate loss\n",
    "                loss = criterion(outputs ,seq_y)\n",
    "                val_loss += loss.item() * bs\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            #print(f\"New best model saved at {best_model_path}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    print(f'Total Model Running Time: {total_time:.2f} seconds')\n",
    "    best_model = Model(input_channels=321, seq_length=seq_len, pred_length = pred_, mlp_hidden_size=mlp_hidden, \n",
    "    output_channels=321, decompose_layers=decompose_layer, dropout=dropout_rate, dilation=dilat, \n",
    "    mode=mt, wave=wt, kernel_size=k_size, \n",
    "    num_encoder_layers=num_encoder_size, nhead=8, \n",
    "    dropout_=dropout_enabled,\n",
    "    skip_=True, pos_encoder_type_ = pos_encoder_type)\n",
    "    best_model.load_state_dict(torch.load(best_model_path))\n",
    "    # Evaluation on test data\n",
    "    best_model.eval()\n",
    "    test_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for seq_x, seq_y, seq_x_mark, seq_y_mark in test_loader:\n",
    "                inputs = seq_x\n",
    "                outputs = model(inputs)  # Model must be adjusted to handle input shape [batch, seq_len, 1]\n",
    "                # Calculate loss\n",
    "                loss = criterion(outputs ,seq_y)\n",
    "                test_loss += loss.item() * bs\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f'The {count}th model done.')\n",
    "    count += 1\n",
    "    print(f'Test Loss for configuration Normal Neu: li={i}, num_encoder_size={num_encoder_size}, skip_enabled={skip_enabled}, '\n",
    "      f'pos_encoder_type={pos_encoder_type}, batch_size={bs}, decompose_layer={decompose_layer}, '\n",
    "      f'kernel_size={k_size}, stride_size={s_size}, mlp_hidden={mlp_hidden}: {test_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
